# Resumen Te√≥rico: Estructuras de Datos y Algoritmos en C++

## üìä Tabla de Contenidos
1. [Algoritmos de Ordenamiento](#ordenamiento)
2. [Algoritmos de B√∫squeda](#busqueda)
3. [√Årboles](#arboles)
4. [Hash Table](#hashtable)
5. [Bitset y Set](#bitset-set)
6. [Grafos](#grafos)

---

## üî¢ 1. Algoritmos de Ordenamiento {#ordenamiento}

### **Bubble Sort (Ordenamiento Burbuja)**

**Algoritmo:**
```
Para i desde 0 hasta n-1:
    Para j desde 0 hasta n-i-2:
        Si arr[j] > arr[j+1]:
            Intercambiar arr[j] y arr[j+1]
```

**Complejidad:**
- Mejor caso: O(n) - si ya est√° ordenado con optimizaci√≥n
- Caso promedio: O(n¬≤)
- Peor caso: O(n¬≤)
- Espacio: O(1)

**Caracter√≠sticas:**
- Estable (mantiene orden relativo de elementos iguales)
- In-place (no requiere memoria adicional)
- Simple pero ineficiente para arrays grandes

---

### **Selection Sort (Ordenamiento por Selecci√≥n)**

**Algoritmo:**
```
Para i desde 0 hasta n-1:
    Encontrar el m√≠nimo en arr[i...n-1]
    Intercambiar arr[i] con el m√≠nimo
```

**Complejidad:**
- Todos los casos: O(n¬≤)
- Espacio: O(1)

**Caracter√≠sticas:**
- **No estable** en implementaci√≥n b√°sica
- Hace menos intercambios que Bubble Sort (m√°ximo n-1)
- √ötil cuando el costo de escritura es alto

---

### **Insertion Sort (Ordenamiento por Inserci√≥n)**

**Algoritmo:**
```
Para i desde 1 hasta n-1:
    key = arr[i]
    j = i - 1
    Mientras j >= 0 y arr[j] > key:
        arr[j+1] = arr[j]
        j = j - 1
    arr[j+1] = key
```

**Complejidad:**
- Mejor caso: O(n) - array casi ordenado
- Caso promedio: O(n¬≤)
- Peor caso: O(n¬≤)
- Espacio: O(1)

**Caracter√≠sticas:**
- Estable
- Eficiente para arrays peque√±os o casi ordenados
- Usado en Timsort (Python) para subarrays peque√±os

---

### **Merge Sort (Ordenamiento por Mezcla)**

**Algoritmo:**
```
MergeSort(arr, inicio, fin):
    Si inicio < fin:
        medio = (inicio + fin) / 2
        MergeSort(arr, inicio, medio)
        MergeSort(arr, medio+1, fin)
        Merge(arr, inicio, medio, fin)
```

**Complejidad:**
- Todos los casos: O(n log n)
- Espacio: O(n)

**Caracter√≠sticas:**
- Estable
- Divide y conquista
- Predecible (siempre O(n log n))
- Requiere espacio adicional

---

### **Quick Sort (Ordenamiento R√°pido)**

**Algoritmo:**
```
QuickSort(arr, bajo, alto):
    Si bajo < alto:
        pivote = Partition(arr, bajo, alto)
        QuickSort(arr, bajo, pivote-1)
        QuickSort(arr, pivote+1, alto)

Partition(arr, bajo, alto):
    pivote = arr[alto]
    i = bajo - 1
    Para j desde bajo hasta alto-1:
        Si arr[j] <= pivote:
            i++
            Intercambiar arr[i] con arr[j]
    Intercambiar arr[i+1] con arr[alto]
    Retornar i+1
```

**Complejidad:**
- Mejor caso: O(n log n)
- Caso promedio: O(n log n)
- Peor caso: O(n¬≤) - array ya ordenado
- Espacio: O(log n) - recursi√≥n

**Caracter√≠sticas:**
- **No estable** en implementaci√≥n b√°sica
- In-place
- Muy eficiente en promedio
- Pivote aleatorio mejora rendimiento

---

### **Heap Sort (Ordenamiento por Mont√≠culo)**

**Algoritmo:**
```
HeapSort(arr):
    Construir max-heap
    Para i desde n-1 hasta 1:
        Intercambiar arr[0] con arr[i]
        Heapify(arr, 0, i)
```

**Complejidad:**
- Todos los casos: O(n log n)
- Espacio: O(1)

**Caracter√≠sticas:**
- **No estable**
- In-place
- No requiere recursi√≥n (puede implementarse iterativamente)
- Bueno cuando memoria es limitada

---

### **Tree Sort (Ordenamiento con √Årbol)**

**Algoritmo:**
```
TreeSort(arr):
    Crear BST vac√≠o
    Para cada elemento en arr:
        Insertar elemento en BST
    
    Realizar recorrido In-Order del BST
    Guardar elementos en arr en orden
```

**Complejidad:**
- Mejor caso: O(n log n) - √°rbol balanceado
- Caso promedio: O(n log n)
- Peor caso: O(n¬≤) - √°rbol degenerado
- Espacio: O(n) - para el √°rbol

**Caracter√≠sticas:**
- Usa √Årbol Binario de B√∫squeda
- El recorrido In-Order produce salida ordenada
- Estable si se implementa correctamente
- Eficiente si el √°rbol est√° balanceado

**Ventajas:**
- Puede ser m√°s eficiente que Quick Sort si el √°rbol est√° balanceado
- √ötil cuando se necesitan inserciones din√°micas

**Desventajas:**
- Requiere memoria adicional para el √°rbol
- Peor caso O(n¬≤) con datos ordenados

---

### **Quick Sort con Pivote Aleatorio (Randomized Quick Sort)**

**Algoritmo:**
```
RandomizedQuickSort(arr, bajo, alto):
    Si bajo < alto:
        pivote = RandomizedPartition(arr, bajo, alto)
        RandomizedQuickSort(arr, bajo, pivote-1)
        RandomizedQuickSort(arr, pivote+1, alto)

RandomizedPartition(arr, bajo, alto):
    // Seleccionar √≠ndice aleatorio entre bajo y alto
    √≠ndiceAleatorio = bajo + rand() % (alto - bajo + 1)
    
    // Intercambiar elemento aleatorio con el √∫ltimo
    Intercambiar arr[√≠ndiceAleatorio] con arr[alto]
    
    // Aplicar partition normal
    pivote = arr[alto]
    i = bajo - 1
    Para j desde bajo hasta alto-1:
        Si arr[j] <= pivote:
            i++
            Intercambiar arr[i] con arr[j]
    Intercambiar arr[i+1] con arr[alto]
    Retornar i+1
```

**Complejidad:**
- Mejor caso: O(n log n)
- Caso promedio: O(n log n)
- Peor caso: O(n¬≤) - muy raro con aleatorizaci√≥n
- Espacio: O(log n) - recursi√≥n

**Caracter√≠sticas:**
- **Aleatorizaci√≥n mejora el rendimiento esperado**
- Evita el peor caso O(n¬≤) con datos ordenados
- No estable en implementaci√≥n b√°sica
- In-place

**Diferencia con Quick Sort b√°sico:**
- Quick Sort b√°sico: pivote = √∫ltimo elemento (o primero)
- Randomized Quick Sort: pivote = elemento aleatorio

**Por qu√© es mejor:**
- Probabilidad de peor caso es extremadamente baja
- Performance consistente independiente del orden de entrada
- O(n log n) esperado para cualquier entrada

---

## üîç 2. Algoritmos de B√∫squeda {#busqueda}

### **B√∫squeda Lineal (Linear Search)**

**Algoritmo:**
```
LinearSearch(arr, n, x):
    Para i desde 0 hasta n-1:
        Si arr[i] == x:
            Retornar i
    Retornar -1
```

**Complejidad:**
- Mejor caso: O(1) - elemento en primera posici√≥n
- Caso promedio: O(n)
- Peor caso: O(n)
- Espacio: O(1)

**Caracter√≠sticas:**
- No requiere array ordenado
- Simple de implementar
- Ineficiente para arrays grandes

---

### **B√∫squeda Binaria (Binary Search)**

**Algoritmo:**
```
BinarySearch(arr, n, x):
    bajo = 0, alto = n - 1
    Mientras bajo <= alto:
        medio = (bajo + alto) / 2
        Si arr[medio] == x:
            Retornar medio
        Si arr[medio] < x:
            bajo = medio + 1
        Sino:
            alto = medio - 1
    Retornar -1
```

**Complejidad:**
- Todos los casos: O(log n)
- Espacio: O(1) iterativo, O(log n) recursivo

**Caracter√≠sticas:**
- **Requiere array ordenado**
- Muy eficiente
- Divide el espacio de b√∫squeda a la mitad en cada paso

---

### **B√∫squeda Ternaria (Ternary Search)**

**Algoritmo:**
```
TernarySearch(arr, bajo, alto, x):
    Si bajo <= alto:
        mid1 = bajo + (alto - bajo) / 3
        mid2 = alto - (alto - bajo) / 3
        
        Si arr[mid1] == x: Retornar mid1
        Si arr[mid2] == x: Retornar mid2
        
        Si x < arr[mid1]:
            TernarySearch(arr, bajo, mid1-1, x)
        Si x > arr[mid2]:
            TernarySearch(arr, mid2+1, alto, x)
        Sino:
            TernarySearch(arr, mid1+1, mid2-1, x)
```

**Complejidad:**
- Todos los casos: O(log‚ÇÉ n) ‚âà 1.58 √ó O(log‚ÇÇ n)
- M√°s comparaciones que b√∫squeda binaria en pr√°ctica

---

### **Jump Search (B√∫squeda por Saltos)**

**Algoritmo:**
```
JumpSearch(arr, n, x):
    salto = ‚àön
    prev = 0
    Mientras arr[min(salto, n) - 1] < x:
        prev = salto
        salto += ‚àön
        Si prev >= n:
            Retornar -1
    
    // B√∫squeda lineal en el bloque
    Para i desde prev hasta min(salto, n):
        Si arr[i] == x:
            Retornar i
    Retornar -1
```

**Complejidad:**
- O(‚àön)
- Espacio: O(1)

**Caracter√≠sticas:**
- Requiere array ordenado
- M√°s lento que b√∫squeda binaria
- Mejor que b√∫squeda lineal

---

### **Interpolation Search (B√∫squeda por Interpolaci√≥n)**

**Algoritmo:**
```
InterpolationSearch(arr, bajo, alto, x):
    Si bajo <= alto y x >= arr[bajo] y x <= arr[alto]:
        // Estimar posici√≥n
        pos = bajo + ((x - arr[bajo]) * (alto - bajo)) / (arr[alto] - arr[bajo])
        
        Si arr[pos] == x: Retornar pos
        Si arr[pos] < x:
            InterpolationSearch(arr, pos+1, alto, x)
        Sino:
            InterpolationSearch(arr, bajo, pos-1, x)
    Retornar -1
```

**Complejidad:**
- Mejor caso: O(log log n) - datos uniformemente distribuidos
- Peor caso: O(n) - datos no uniformes
- Espacio: O(1)

---

## üå≤ 3. √Årboles {#arboles}

### **√Årbol Binario (Binary Tree)**

**Estructura:**
```cpp
struct Nodo {
    int dato;
    Nodo* izq;
    Nodo* der;
};
```

**Operaciones:**
- Inserci√≥n: O(n) - peor caso √°rbol degenerado
- B√∫squeda: O(n)
- Eliminaci√≥n: O(n)

---

### **√Årbol Binario de B√∫squeda (BST)**

**Propiedad:** Para cada nodo:
- Sub√°rbol izquierdo: todos los valores < nodo
- Sub√°rbol derecho: todos los valores > nodo

**Recorridos:**

1. **In-Order (Izq ‚Üí Ra√≠z ‚Üí Der):**
   ```
   InOrder(nodo):
       Si nodo != NULL:
           InOrder(nodo->izq)
           Visitar(nodo)
           InOrder(nodo->der)
   ```
   - Resultado: elementos en orden ascendente
   - Complejidad: O(n)

2. **Pre-Order (Ra√≠z ‚Üí Izq ‚Üí Der):**
   ```
   PreOrder(nodo):
       Si nodo != NULL:
           Visitar(nodo)
           PreOrder(nodo->izq)
           PreOrder(nodo->der)
   ```
   - √ötil para copiar √°rbol
   - Complejidad: O(n)

3. **Post-Order (Izq ‚Üí Der ‚Üí Ra√≠z):**
   ```
   PostOrder(nodo):
       Si nodo != NULL:
           PostOrder(nodo->izq)
           PostOrder(nodo->der)
           Visitar(nodo)
   ```
   - √ötil para eliminar √°rbol
   - Complejidad: O(n)

4. **Level-Order (Por Niveles):**
   ```
   LevelOrder(ra√≠z):
       Cola Q
       Q.encolar(ra√≠z)
       Mientras !Q.vac√≠a():
           nodo = Q.desencolar()
           Visitar(nodo)
           Si nodo->izq: Q.encolar(nodo->izq)
           Si nodo->der: Q.encolar(nodo->der)
   ```
   - Usa BFS
   - Complejidad: O(n)

**Complejidad BST:**
- Inserci√≥n: O(h) donde h = altura
  - Mejor caso: O(log n) - balanceado
  - Peor caso: O(n) - degenerado (lista)
- B√∫squeda: O(h)
- Eliminaci√≥n: O(h)
- Espacio: O(n)

---

### **√Årbol AVL (Auto-balanceado)**

**Propiedad:** 
- Factor de balance: |altura(izq) - altura(der)| ‚â§ 1 para cada nodo

**Rotaciones:**
1. **Simple Derecha (LL):** hijo izq del izq desbalanceado
2. **Simple Izquierda (RR):** hijo der del der desbalanceado
3. **Doble Izq-Der (LR):** hijo der del izq desbalanceado
4. **Doble Der-Izq (RL):** hijo izq del der desbalanceado

**Complejidad:**
- Inserci√≥n: O(log n)
- B√∫squeda: O(log n)
- Eliminaci√≥n: O(log n)
- Espacio: O(n)
- Rebalanceo: O(log n)

**Ventajas:**
- B√∫squedas m√°s r√°pidas que BST no balanceado
- Garantiza altura logar√≠tmica

**Desventajas:**
- Inserciones/eliminaciones m√°s lentas (por rotaciones)
- Mayor complejidad de implementaci√≥n

---

### **√Årbol Rojo-Negro (Red-Black Tree)**

**Propiedades:**
1. Cada nodo es rojo o negro
2. Ra√≠z es negra
3. Hojas (NULL) son negras
4. Hijos de nodo rojo son negros
5. Todo camino de nodo a hojas tiene mismo n√∫mero de nodos negros

**Complejidad:**
- Inserci√≥n: O(log n)
- B√∫squeda: O(log n)
- Eliminaci√≥n: O(log n)
- Espacio: O(n)

**Comparaci√≥n AVL vs Red-Black:**
- AVL: m√°s balanceado ‚Üí b√∫squedas m√°s r√°pidas
- Red-Black: menos rotaciones ‚Üí inserciones/eliminaciones m√°s r√°pidas

---

### **Heap (Mont√≠culo)**

**Max-Heap:** Padre ‚â• hijos  
**Min-Heap:** Padre ‚â§ hijos

**Propiedades:**
- √Årbol binario completo (se llena de izq a der)
- Se implementa t√≠picamente con array

**√çndices en array:**
- Padre de i: (i-1)/2
- Hijo izquierdo: 2i + 1
- Hijo derecho: 2i + 2

**Operaciones:**
- Inserci√≥n: O(log n)
- Extraer m√°x/m√≠n: O(log n)
- Obtener m√°x/m√≠n: O(1)
- Construir heap: O(n)
- Heapify: O(log n)

**Usos:**
- Priority Queue
- Heap Sort
- Algoritmo de Dijkstra
- Algoritmo de Prim

---

### **Trie (√Årbol de Prefijos)**

**Estructura:**
```cpp
struct NodoTrie {
    NodoTrie* hijos[26];  // para alfabeto
    bool esFinal;
};
```

**Complejidad:**
- Inserci√≥n: O(m) donde m = longitud de palabra
- B√∫squeda: O(m)
- Eliminaci√≥n: O(m)
- Espacio: O(ALPHABET_SIZE √ó m √ó n) en peor caso

**Usos:**
- Autocompletado
- Corrector ortogr√°fico
- B√∫squeda de prefijos
- IP routing

---

## üîê 4. Hash Table {#hashtable}

### **Concepto**

Estructura que mapea claves a valores usando una funci√≥n hash:
```
√≠ndice = hash(clave) % tama√±o_tabla
```

### **Funci√≥n Hash**

**Caracter√≠sticas deseables:**
- Determinista
- Distribuci√≥n uniforme
- R√°pida de calcular
- Minimiza colisiones

**Ejemplos:**
```cpp
// Divisi√≥n
hash(k) = k % m

// Multiplicaci√≥n
hash(k) = floor(m √ó (k √ó A % 1))  // 0 < A < 1

// String hashing
hash(s) = Œ£(s[i] √ó p^i) % m  // p = primo
```

### **Manejo de Colisiones**

#### **1. Chaining (Encadenamiento)**
```
Tabla[i] ‚Üí [elem1] ‚Üí [elem2] ‚Üí [elem3] ‚Üí NULL
```

**Complejidad:**
- Inserci√≥n: O(1)
- B√∫squeda: O(1 + Œ±) donde Œ± = factor de carga (n/m)
- Eliminaci√≥n: O(1 + Œ±)
- Espacio: O(n + m)

**Factor de carga:** Œ± = n/m
- n = n√∫mero de elementos
- m = tama√±o de tabla
- Œ± peque√±o ‚Üí menos colisiones

#### **2. Open Addressing (Direccionamiento Abierto)**

**a) Linear Probing:**
```
h(k, i) = (h'(k) + i) % m
```
- Problema: clustering primario

**b) Quadratic Probing:**
```
h(k, i) = (h'(k) + c‚ÇÅi + c‚ÇÇi¬≤) % m
```
- Reduce clustering

**c) Double Hashing:**
```
h(k, i) = (h‚ÇÅ(k) + i √ó h‚ÇÇ(k)) % m
```
- Mejor distribuci√≥n

**Complejidad Open Addressing:**
- Inserci√≥n: O(1/(1-Œ±))
- B√∫squeda: O(1/(1-Œ±))
- Œ± debe ser < 1 (tabla nunca llena completamente)

### **Rehashing**

Cuando Œ± supera umbral (t√≠picamente 0.7):
```
1. Crear nueva tabla (tama√±o √ó 2)
2. Reinsertar todos los elementos
3. Complejidad: O(n)
```

### **Comparaci√≥n**

| Operaci√≥n | Promedio | Peor Caso |
|-----------|----------|-----------|
| B√∫squeda  | O(1)     | O(n)      |
| Inserci√≥n | O(1)     | O(n)      |
| Eliminaci√≥n | O(1)   | O(n)      |

---

## üî¢ 5. Bitset y Set {#bitset-set}

### **Bitset**

**Concepto:** Array de bits compacto

**Operaciones:**
```cpp
bitset<8> b("10101010");
b.set(i)      // Poner bit i en 1
b.reset(i)    // Poner bit i en 0
b.flip(i)     // Invertir bit i
b.test(i)     // Consultar bit i
b.count()     // Contar bits en 1
b.any()       // ¬øAlg√∫n bit en 1?
b.all()       // ¬øTodos los bits en 1?
b.none()      // ¬øNing√∫n bit en 1?
```

**Operaciones de bits:**
```cpp
b1 & b2   // AND
b1 | b2   // OR
b1 ^ b2   // XOR
~b1       // NOT
b1 << n   // Shift izquierda
b1 >> n   // Shift derecha
```

**Complejidad:**
- Todas las operaciones: O(1) o O(n/w) donde w = tama√±o de palabra
- Espacio: n bits (compacto)

**Usos:**
- Representar conjuntos peque√±os
- M√°scaras de bits
- Optimizaci√≥n de memoria
- Algoritmos con estados binarios

---

### **Set (Conjunto)**

**Implementaci√≥n en C++:** √Årbol Rojo-Negro (ordenado)

**Operaciones:**
```cpp
set<int> s;
s.insert(x)    // Insertar
s.erase(x)     // Eliminar
s.find(x)      // Buscar
s.count(x)     // ¬øExiste? (0 o 1)
s.size()       // Tama√±o
s.empty()      // ¬øVac√≠o?
s.clear()      // Limpiar
```

**Complejidad:**
- Inserci√≥n: O(log n)
- B√∫squeda: O(log n)
- Eliminaci√≥n: O(log n)
- Espacio: O(n)

**Caracter√≠sticas:**
- Elementos √∫nicos
- Ordenados autom√°ticamente
- No permite duplicados
- Iteradores bidireccionales

---

### **Unordered Set**

**Implementaci√≥n:** Hash Table

**Complejidad:**
- Inserci√≥n: O(1) promedio, O(n) peor caso
- B√∫squeda: O(1) promedio, O(n) peor caso
- Eliminaci√≥n: O(1) promedio, O(n) peor caso
- Espacio: O(n)

**Caracter√≠sticas:**
- No ordenado
- M√°s r√°pido que set en promedio
- Elementos √∫nicos

**Comparaci√≥n Set vs Unordered Set:**

| Aspecto | Set | Unordered Set |
|---------|-----|---------------|
| Implementaci√≥n | √Årbol RB | Hash Table |
| Orden | S√≠ | No |
| B√∫squeda | O(log n) | O(1) promedio |
| Iteraci√≥n | Ordenada | Sin orden |
| Uso de memoria | Menor | Mayor |

---

### **Multiset**

**Diferencia con Set:** Permite elementos duplicados

**Complejidad:** Igual que set
- Inserci√≥n: O(log n)
- B√∫squeda: O(log n)
- Eliminaci√≥n: O(log n)

**Usos:**
- Contar frecuencias manteniendo orden
- Priority queue con duplicados

---

## üìä 6. Grafos {#grafos}

### **Definiciones B√°sicas**

- **Grafo:** G = (V, E) donde V = v√©rtices, E = aristas
- **Grado:** n√∫mero de aristas conectadas a un v√©rtice
- **Camino:** secuencia de v√©rtices conectados
- **Ciclo:** camino que empieza y termina en el mismo v√©rtice
- **Conexo:** existe camino entre cualquier par de v√©rtices
- **Componente conexa:** subgrafo conexo maximal

**Tipos:**
- **Dirigido vs No dirigido**
- **Ponderado vs No ponderado**
- **C√≠clico vs Ac√≠clico (DAG)**
- **Conexo vs Desconexo**

---

### **Representaciones**

#### **1. Matriz de Adyacencia**

```cpp
int adj[V][V];
adj[i][j] = 1 si existe arista entre i y j
```

**Complejidad:**
- Espacio: O(V¬≤)
- Verificar arista: O(1)
- Obtener vecinos: O(V)
- Agregar arista: O(1)

**Ventajas:**
- Consulta r√°pida de aristas
- Simple para grafos densos

**Desventajas:**
- Desperdicia memoria en grafos dispersos
- Iterar vecinos es lento

---

#### **2. Lista de Adyacencia**

```cpp
vector<int> adj[V];
// o
struct Nodo {
    int dato;
    Nodo* siguiente;
};
Nodo* adj[V];
```

**Complejidad:**
- Espacio: O(V + E)
- Verificar arista: O(grado)
- Obtener vecinos: O(grado)
- Agregar arista: O(1)

**Ventajas:**
- Eficiente en memoria para grafos dispersos
- R√°pido para iterar vecinos

**Desventajas:**
- Consultar arista espec√≠fica es m√°s lenta

---

### **Algoritmos de Recorrido**

#### **BFS (Breadth-First Search)**

**Algoritmo:**
```
BFS(grafo, origen):
    Cola Q
    Marcar origen como visitado
    Q.encolar(origen)
    
    Mientras !Q.vac√≠a():
        u = Q.desencolar()
        Para cada vecino v de u:
            Si v no visitado:
                Marcar v como visitado
                Q.encolar(v)
                padre[v] = u
```

**Complejidad:**
- Tiempo: O(V + E)
- Espacio: O(V)

**Propiedades:**
- Encuentra camino m√°s corto en grafos no ponderados
- Explora por niveles
- Usa cola (FIFO)

**Usos:**
- Camino m√°s corto sin pesos
- Verificar conexidad
- √Årbol de expansi√≥n
- Nivel de nodos

---

#### **DFS (Depth-First Search)**

**Algoritmo (Recursivo):**
```
DFS(grafo, u, visitados):
    Marcar u como visitado
    Para cada vecino v de u:
        Si v no visitado:
            padre[v] = u
            DFS(grafo, v, visitados)
```

**Algoritmo (Iterativo):**
```
DFS_Iterativo(grafo, origen):
    Pila S
    S.apilar(origen)
    
    Mientras !S.vac√≠a():
        u = S.desapilar()
        Si u no visitado:
            Marcar u como visitado
            Para cada vecino v de u:
                Si v no visitado:
                    S.apilar(v)
```

**Complejidad:**
- Tiempo: O(V + E)
- Espacio: O(V)

**Propiedades:**
- Explora en profundidad antes de retroceder
- Usa pila (recursi√≥n o expl√≠cita)
- No garantiza camino m√°s corto

**Usos:**
- Detectar ciclos
- Ordenamiento topol√≥gico
- Componentes fuertemente conexas
- Resolver laberintos

---

### **Algoritmos de Camino M√°s Corto**

#### **Dijkstra**

**Algoritmo:**
```
Dijkstra(grafo, origen):
    distancia[todos] = ‚àû
    distancia[origen] = 0
    PriorityQueue PQ
    PQ.insertar(origen, 0)
    
    Mientras !PQ.vac√≠a():
        u = PQ.extraerM√≠nimo()
        
        Para cada vecino v de u con peso w:
            Si distancia[u] + w < distancia[v]:
                distancia[v] = distancia[u] + w
                padre[v] = u
                PQ.insertar(v, distancia[v])
```

**Complejidad:**
- Con heap binario: O((V + E) log V)
- Con heap Fibonacci: O(E + V log V)
- Espacio: O(V)

**Requisitos:**
- **No funciona con pesos negativos**
- Grafos dirigidos o no dirigidos

**Caracter√≠sticas:**
- Algoritmo greedy
- Usa priority queue (min-heap)
- Encuentra camino m√°s corto desde un origen a todos los dem√°s

---

#### **Bellman-Ford**

**Algoritmo:**
```
BellmanFord(grafo, origen):
    distancia[todos] = ‚àû
    distancia[origen] = 0
    
    // Relajar todas las aristas V-1 veces
    Para i desde 1 hasta V-1:
        Para cada arista (u, v) con peso w:
            Si distancia[u] + w < distancia[v]:
                distancia[v] = distancia[u] + w
                padre[v] = u
    
    // Detectar ciclos negativos
    Para cada arista (u, v) con peso w:
        Si distancia[u] + w < distancia[v]:
            Retornar "Ciclo negativo detectado"
```

**Complejidad:**
- Tiempo: O(V √ó E)
- Espacio: O(V)

**Caracter√≠sticas:**
- **Funciona con pesos negativos**
- Detecta ciclos negativos
- M√°s lento que Dijkstra
- Programaci√≥n din√°mica

---

#### **Floyd-Warshall**

**Algoritmo:**
```
FloydWarshall(grafo):
    dist[V][V]
    // Inicializar
    Para i, j:
        dist[i][j] = peso(i, j) si existe arista
        dist[i][j] = ‚àû si no existe
        dist[i][i] = 0
    
    // Algoritmo principal
    Para k desde 0 hasta V-1:
        Para i desde 0 hasta V-1:
            Para j desde 0 hasta V-1:
                Si dist[i][k] + dist[k][j] < dist[i][j]:
                    dist[i][j] = dist[i][k] + dist[k][j]
```

**Complejidad:**
- Tiempo: O(V¬≥)
- Espacio: O(V¬≤)

**Caracter√≠sticas:**
- Encuentra caminos m√°s cortos **entre todos los pares**
- Funciona con pesos negativos
- Detecta ciclos negativos
- Programaci√≥n din√°mica

---

### **√Årbol de Expansi√≥n M√≠nima (MST)**

#### **Prim**

**Algoritmo:**
```
Prim(grafo):
    MST = vac√≠o
    visitados = {origen}
    PQ = todas las aristas de origen
    
    Mientras |MST| < V-1:
        (u, v, peso) = PQ.extraerM√≠nimo()
        Si v no visitado:
            Agregar (u, v) a MST
            Marcar v como visitado
            Agregar aristas de v a PQ
```

**Complejidad:**
- Con heap binario: O(E log V)
- Con heap Fibonacci: O(E + V log V)
- Espacio: O(V + E)

**Caracter√≠sticas:**
- Similar a Dijkstra
- Greedy
- Mejor
